class: middle, center, title-slide

# –î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è —ñ –ø—Ä–æ–µ–∫—Ç—É–≤–∞–Ω–Ω—è —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏—Ö —Å–∏—Å—Ç–µ–º

–õ–µ–∫—Ü—ñ—è 1: –í—Å—Ç—É–ø

<br><br>
–ö–æ—á—É—Ä–∞ –Æ—Ä—ñ–π –ü–µ—Ç—Ä–æ–≤–∏—á<br>
[iuriy.kochura@gmail.com](mailto:iuriy.kochura@gmail.com) <br>
<a href="https://t.me/y_kochura">@y_kochura</a> <br>


---

# –°—å–æ–≥–æ–¥–Ω—ñ

- –Ü–Ω—Ç–µ–ª–µ–∫—Ç vs —à—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç
- –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É —Ç–∞ –ø–∞—Ä–∞–¥–∏–≥–º–∞
- –¢–∏–ø–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è
- –ö–æ–Ω—Ü–µ–ø—Ü—ñ—è –≥–ª–∏–±–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è
- –ü—Ä–∏–∫–ª–∞–¥–∏ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –≥–ª–∏–±–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è
- –ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω: –ø—Ä—è–º–µ —Ç–∞ –∑–≤–æ—Ä–æ—Ç–Ω–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è
- –ó–∞–≥–∞–ª—å–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó

---

class: blue-slide, middle, center
count: false

.larger-xx[–®—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç]

---

class: middle

# –ß–∏ –º–æ–∂–µ –º–∞—à–∏–Ω–∞ –¥—É–º–∞—Ç–∏?
.grid[
.kol-2-3[
.width-90[![](figures/lec1/computing-machinery-and-intelligence.jpg)]

.pull-right[&mdash; Alan Turing, 1950]
]

.kol-1-3[.center.circle.width-70[![](figures/lec1/turing.jpg)]

.center.smaller-xxx[Image source: [biography](https://www.biography.com/scientist/alan-turing)]
  ]
]

.footnote[Credits: [Alan Turing](https://academic.oup.com/mind/article/LIX/236/433/986238), 1950.]

???

–©–æ —Ç–∞–∫–µ —Å–≤—ñ–¥–æ–º—ñ—Å—Ç—å?
–ß–∏ –º–æ–∂—É—Ç—å –º–∞—à–∏–Ω–∏ –¥—É–º–∞—Ç–∏?

–ë—Ä–∏—Ç–∞–Ω—Å—å–∫–∏–π –Ω–∞—É–∫–æ–≤–µ—Ü—å –ê–ª–∞–Ω –¢—é—Ä—ñ–Ω–≥ –∑–∞–¥–∞–≤–∞–≤—Å—è –ø–∏—Ç–∞–Ω–Ω—è–º
—á–∏ –º–æ–∂–µ –∫–æ–º–ø'—é—Ç–µ—Ä —Ä–æ–∑–º–æ–≤–ª—è—Ç–∏, —è–∫ –ª—é–¥–∏–Ω–∞?

–¶–µ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–∏–∑–≤–µ–ª–æ –¥–æ —ñ–¥–µ—ó –æ—Ü—ñ–Ω–∫–∏ —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É, —â–æ, —è–∫ –≤—ñ–¥–æ–º–æ, –≤—Ç—ñ–ª–∏–ª–æ—Å—è —É –≤—ñ–¥–æ–º–æ–º—É —Ç–µ—Å—Ç—ñ –¢—é—Ä—ñ–Ω–≥–∞. –£ 1950 —Ä–æ—Ü—ñ –≤ —Å—Ç–∞—Ç—Ç—ñ "–û–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω–∞ —Ç–µ—Ö–Ω—ñ–∫–∞ —Ç–∞ —ñ–Ω—Ç–µ–ª–µ–∫—Ç" –¢—é—Ä—ñ–Ω–≥ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞–≤ –Ω–∞—Å—Ç—É–ø–Ω—É –≥—Ä—É.
–°—É–¥–¥—è-–ª—é–¥–∏–Ω–∞ –ø–µ—Ä–µ–ø–∏—Å—É—î—Ç—å—Å—è –∑ —É—á–∞—Å–Ω–∏–∫–∞–º–∏ (–≥—Ä–∞–≤—Ü—è–º–∏), —è–∫–∏—Ö –≤—ñ–Ω –Ω–µ –±–∞—á–∏—Ç—å, —Ç–∞ –æ—Ü—ñ–Ω—é—î —ó—Ö–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ. –©–æ–± –ø—Ä–æ–π—Ç–∏ —Ç–µ—Å—Ç, –∫–æ–º–ø'—é—Ç–µ—Ä –ø–æ–≤–∏–Ω–µ–Ω –±—É—Ç–∏ —É –∑–º–æ–∑—ñ –ø—ñ–¥–º—ñ–Ω–∏—Ç–∏ –æ–¥–Ω–æ–≥–æ –∑ —É—á–∞—Å–Ω–∏–∫—ñ–≤, –Ω–µ –ø–æ–º—ñ—Ç–∏–≤—à–∏ –ø—ñ–¥–º—ñ–Ω–∏. –Ü–Ω—à–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, –∫–æ–º–ø'—é—Ç–µ—Ä –≤–≤–∞–∂–∞—Ç–∏–º–µ—Ç—å—Å—è —Ä–æ–∑—É–º–Ω–∏–º, —è–∫—â–æ –π–æ–≥–æ —Ä–æ–∑–º–æ–≤—É –Ω–µ–º–æ–∂–ª–∏–≤–æ –±—É–¥–µ –ª–µ–≥–∫–æ –≤—ñ–¥—Ä—ñ–∑–Ω–∏—Ç–∏ –≤—ñ–¥ –ª—é–¥—Å—å–∫–æ—ó.

---

class: middle
count: false


.smaller-x.italic[
In the process of trying to imitate an adult human mind we are bound to think a good deal about
the process which has brought it to the state that it is in. We may notice three components,

  a. The initial state of the mind, say at birth,

  b. The education to which it has been subjected,

  c. Other experience, not to be described as education, to which it has been subjected.

Instead of trying to produce a programme to simulate the adult mind, why not rather try to produce
one which simulates the child‚Äôs? If this were then subjected to an appropriate course of education one
would obtain the adult brain. Presumably the child-brain is something like a note-book as one buys
it from the stationers. Rather little mechanism, and lots of blank sheets. (Mechanism and writing
are from our point of view almost synonymous.) Our hope is that there is so little mechanism in
the child-brain that something like it can be easily programmed.

]

.pull-right[&mdash; Alan Turing, 1950]

.footnote[Credits: [Alan Turing](https://academic.oup.com/mind/article/LIX/236/433/986238), 1950.]

???

–ù–∞–º–∞–≥–∞—é—á–∏—Å—å —ñ–º—ñ—Ç—É–≤–∞—Ç–∏ —Ä–æ–∑—É–º –¥–æ—Ä–æ—Å–ª–æ—ó –ª—é–¥–∏–Ω–∏, –º–∏ –∑–æ–±–æ–≤‚Äô—è–∑–∞–Ω—ñ –±–∞–≥–∞—Ç–æ –¥—É–º–∞—Ç–∏ –ø—Ä–æ –ø—Ä–æ—Ü–µ—Å, —è–∫–∏–π –ø—Ä–∏–≤—ñ–≤ –π–æ–≥–æ –¥–æ —Å—Ç–∞–Ω—É, –≤ —è–∫–æ–º—É –≤—ñ–Ω –ø–µ—Ä–µ–±—É–≤–∞—î. –ú–∏ –º–æ–∂–µ–º–æ –ø–æ–º—ñ—Ç–∏—Ç–∏ —Ç—Ä–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏:

a. –ü–æ—á–∞—Ç–∫–æ–≤–∏–π —Å—Ç–∞–Ω —Ä–æ–∑—É–º—É, —Å–∫–∞–∂—ñ–º–æ, –ø—Ä–∏ –Ω–∞—Ä–æ–¥–∂–µ–Ω–Ω—ñ

b. –û—Å–≤—ñ—Ç–∞, —è–∫—ñ–π –ª—é–¥–∏–Ω–∞ –±—É–ª–∞ –ø—ñ–¥–¥–∞–Ω–∞,

–≤. –Ü–Ω—à–∏–π –¥–æ—Å–≤—ñ–¥, —è–∫–∏–π –Ω–µ –º–æ–∂–Ω–∞ –Ω–∞–∑–≤–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è–º, —è–∫–æ–º—É –≤—ñ–Ω –±—É–≤ –ø—ñ–¥–¥–∞–Ω–∏–π.

–ó–∞–º—ñ—Å—Ç—å —Ç–æ–≥–æ, —â–æ–± –Ω–∞–º–∞–≥–∞—Ç–∏—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º—É –¥–ª—è –º–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è —Ä–æ–∑—É–º—É –¥–æ—Ä–æ—Å–ª–æ–≥–æ, —á–æ–º—É –± –Ω–µ —Å–ø—Ä–æ–±—É–≤–∞—Ç–∏ —Å—Ç–≤–æ—Ä–∏—Ç–∏ —Ç–∞–∫—É, —è–∫–∞ –º–æ–¥–µ–ª—é—î —Ä–æ–∑—É–º –¥–∏—Ç–∏–Ω–∏? –Ø–∫–±–∏ —Ü–µ –ø–æ—Ç—ñ–º –±—É–ª–æ –ø—ñ–¥–¥–∞–Ω–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ–º—É –∫—É—Ä—Å—É –æ—Å–≤—ñ—Ç–∏, –º–æ–∂–Ω–∞ –±—É–ª–æ –± –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–æ—Ä–æ—Å–ª–∏–π –º–æ–∑–æ–∫. –Ü–º–æ–≤—ñ—Ä–Ω–æ, –¥–∏—Ç—è—á–∏–π –º–æ–∑–æ–∫ ‚Äî —Ü–µ —â–æ—Å—å –Ω–∞ –∫—à—Ç–∞–ª—Ç –∑–æ—à–∏—Ç–∞, –æ—Å–∫—ñ–ª—å–∫–∏ –π–æ–≥–æ –∫—É–ø—É—é—Ç—å —É –∫–∞–Ω—Ü—Ç–æ–≤–∞—Ä–∞—Ö. –î–æ—Å–∏—Ç—å –º–∞–ª–µ–Ω—å–∫–∏–π –º–µ—Ö–∞–Ω—ñ–∑–º —ñ –±–∞–≥–∞—Ç–æ —á–∏—Å—Ç–∏—Ö –∞—Ä–∫—É—à—ñ–≤. (–ú–µ—Ö–∞–Ω—ñ–∑–º —ñ –ø–∏—Å—å–º–æ –∑ –Ω–∞—à–æ—ó —Ç–æ—á–∫–∏ –∑–æ—Ä—É –º–∞–π–∂–µ —Å–∏–Ω–æ–Ω—ñ–º–∏.) –ú–∏ —Å–ø–æ–¥—ñ–≤–∞—î–º–æ—Å—å, —â–æ –≤ –¥–∏—Ç—è—á–æ–º—É –º–æ–∑–∫—É –Ω–∞—Å—Ç—ñ–ª—å–∫–∏ –º–∞–ª–æ –º–µ—Ö–∞–Ω—ñ–∑–º—ñ–≤, —â–æ —â–æ—Å—å –ø–æ–¥—ñ–±–Ω–µ –º–æ–∂–Ω–∞ –ª–µ–≥–∫–æ –∑–∞–ø—Ä–æ–≥—Ä–∞–º—É–≤–∞—Ç–∏.

---

class: middle

# –©–æ —Ç–∞–∫–µ —ñ–Ω—Ç–µ–ª–µ–∫—Ç?

- –Ü–Ω—Ç–µ–ª–µ–∫—Ç &mdash; —Ü–µ –ø—Ä–æ –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å

.bold.center.larger-x[–Ω–∞–≤—á–∞—Ç–∏—Å—è –ø—Ä–∏–π–º–∞—Ç–∏ —Ä—ñ—à–µ–Ω–Ω—è –¥–ª—è –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è —Ü—ñ–ª–µ–π]
   

- –ù–∞–≤—á–∞–Ω–Ω—è, –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω–Ω—è, —Ç–∞ —Ü—ñ–ª—ñ —î –∫–ª—é—á–æ–≤–∏–º–∏

---

class: middle

# –©–æ —Ç–∞–∫–µ —à—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç?

- –£ —à–∏—Ä–æ–∫–æ–º—É —Å–µ–Ω—Å—ñ 

.bold.larger-x[–ë—É–¥—å-—è–∫–∞ —Ç–µ—Ö–Ω—ñ–∫–∞, —è–∫–∞ –¥–æ–∑–≤–æ–ª—è—î –∫–æ–º–ø'—é—Ç–µ—Ä–∞–º —ñ–º—ñ—Ç—É–≤–∞—Ç–∏ –ø–æ–≤–µ–¥—ñ–Ω–∫—É –ª—é–¥–∏–Ω–∏]
   
---

class: middle

# –©–æ —Ç–∞–∫–µ —à—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç?

- –£ –≤—É–∑—å–∫–æ–º—É —Å–µ–Ω—Å—ñ 

.alert[
.bold.larger-x[**–®—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç** &mdash; –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å —ñ–Ω–∂–µ–Ω–µ—Ä–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏ –æ–±—Ä–æ–±–ª—è—Ç–∏, –∑–∞—Å—Ç–æ—Å–æ–≤—É–≤–∞—Ç–∏ —Ç–∞ –≤–¥–æ—Å–∫–æ–Ω–∞–ª—é–≤–∞—Ç–∏ –∑–¥–æ–±—É—Ç—ñ –∑–Ω–∞–Ω–Ω—è —Ç–∞ –≤–º—ñ–Ω–Ω—è.]]

- **–ó–Ω–∞–Ω–Ω—è** &mdash; —Ü–µ —Ñ–∞–∫—Ç–∏, —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —Ç–∞ –Ω–∞–≤–∏—á–∫–∏, –Ω–∞–±—É—Ç—ñ —á–µ—Ä–µ–∑ –¥–æ—Å–≤—ñ–¥ –∞–±–æ –Ω–∞–≤—á–∞–Ω–Ω—è.

.footnote[Credits: [ISO/IEC TR 24028:2020(en)](https://www.iso.org/obp/ui/#iso:std:iso-iec:tr:24028:ed-1:v1:en:term:3.4), 2020.]

---

class: middle

## –ö–æ—Ä–æ—Ç–∫–∞ —ñ—Å—Ç–æ—Ä—ñ—è

.smaller-xx[
- 1940‚Äî1952: Early days
  - 1943: McCulloch & Pitts: Boolean circuit model of brain
  - 1950: Turing's ''Computing Machinery and Intelligence''

- 1952‚Äì1956:  The birth of AI
  - 1950s: Early AI programs, including Samuel's checkers program,
Newell & Simon's Logic Theorist, Gelernter's Geometry Engine
  - 1956: Dartmouth meeting: ''Artificial Intelligence'' adopted

- 1956‚Äì1974: The golden years 
  - 1958: Frank Rosenblatt invented [perceptron](https://en.wikipedia.org/wiki/Perceptron) (simple neural network)
  - 1964: [Bobrow's program](https://en.wikipedia.org/wiki/STUDENT_(computer_program) that solves algebra word problems
  - 1965: Robinson's complete algorithm for logical reasoning

- 1974‚Äì1980: The first AI winter

- 1980‚Äì1987: Expert systems industry boom
- 1987‚Äî1993: Expert systems industry busts: the second AI winter 

- 1993‚Äì2011: Statistical approaches 
  - Resurgence of probability, focus on uncertainty
  - General increase in technical depth
  - Intelligent agents

- 2011‚Äìpresent: Deep Learning, Big Data and AI
  - Big data, big compute, neural networks
  - AI used in many industries
]

.footnote[Credits: [Wikipedia - History of artificial intelligence](https://en.wikipedia.org/wiki/History_of_artificial_intelligence#Deep_learning)]

---

class: middle

# AI &mdash; –±–∞–≥–∞—Ç–∞ –≥–∞–ª—É–∑—å

.center.width-90[![](figures/lec1/Fields-of-artificial-intelligence-10.png)]

.footnote[Image Source: [Marizel B. and Ma. Louella Salenga](https://www.researchgate.net/publication/324183626_Bitter_Melon_Crop_Yield_Prediction_using_Machine_Learning_Algorithm), 2018.]

---

class: middle

.center.width-90[![](figures/lec1/ML-capabilities.png)]

.footnote[Image Source: [Why you Might Want to use Machine Learning](https://ml-ops.org/content/motivation).]

---

class: middle

.center.width-50[![](figures/lec1/AndrewNG.webp)]

"Just as electricity transformed almost everything 100 years ago, today I actually have a hard time thinking of an industry that I don't think AI will transform in the next several years."

.pull-right[&mdash; Andrew Ng]

.footnote[Credits: [Andrew Ng: Artificial Intelligence is the New Electricity](https://www.youtube.com/watch?v=21EiKfQYZXc), 2017.]

---

class: blue-slide, middle, center
count: false

.larger-xx[–ú–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è]

---

class: middle, center

# –©–æ —Ç–∞–∫–µ –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è?

---

class: middle

# –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –ê—Ä—Ç—É—Ä –°–µ–º—é–µ–ª—å

.center[
.width-100[![](figures/lec1/def1.png)]
]

---

class: middle

# –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –¢–æ–º –ú—ñ—Ç—á–µ–ª–ª


–¢–æ–º –ú—ñ—Ç—á–µ–ª–ª (1998): –ö–æ–º–ø‚Äô—é—Ç–µ—Ä–Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–∞, —è–∫–∞ —É—á–∏—Ç—å—Å—è –∑ –¥–æ—Å–≤i–¥—É **E** –ø–æ –≤i–¥–Ω–æ—à–µ–Ω–Ω—é –¥–æ –¥–µ—è–∫–æ–≥–æ
–∫–ª–∞—Å—É –∑–∞–¥–∞—á **T** —Ç–∞ –ºi—Ä–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Çi **P** –Ω–∞–∑–∏–≤–∞—î—Ç—å—Å—è –º–∞—à–∏–Ω–Ω–∏–º –Ω–∞–≤—á–∞–Ω–Ω—è–º, —è–∫—â–æ —ó—ó –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ωi—Å—Ç—å —É –∑–∞–¥–∞—á–∞—Ö
–∑ **T**, —â–æ –≤–∏–ºi—Ä—é—î—Ç—å—Å—è –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é **P**, –ø–æ–∫—Ä–∞—â—É—î—Ç—å—Å—è –∑ –¥–æ—Å–≤i–¥–æ–º **E**.

.right[
.width-30[![](figures/lec1/tm.png)]
]

  - –î–æ—Å–≤—ñ–¥ (–¥–∞–Ω—ñ): —ñ–≥—Ä–∏ –≤ —è–∫—ñ –≥—Ä–∞—î –ø—Ä–æ–≥—Ä–∞–º–∞ —Å–∞–º–∞ –∑ —Å–æ–±–æ—é
  - –í–∏–º—ñ—Ä –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ: –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –≤–∏–≥—Ä–∞—à—É

---


class: middle

# –ö–ª–∞—Å–∏—á–Ω–µ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω vs –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/mlVSprograming1.png)]
]

???

–ö–æ–º–ø‚Äô—é—Ç–µ—Ä–∏ —Ç–∞ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–æ–ø–æ–º–∞–≥–∞—é—Ç—å –Ω–∞–º –¥–æ—Å—è–≥–∞—Ç–∏ –±i–ª—å—à —Å–∫–ª–∞–¥–Ω–∏—Ö —Üi–ª–µ–π i –∫—Ä–∞—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Çi–≤ —É –≤–∏—Äi—à–µ–Ω–Ωi
–ø—Ä–æ–±–ª–µ–º, –Ωi–∂ –º–∏ –º–æ–≥–ª–∏ –± –¥–æ—Å—è–≥—Ç–∏ —Å–∞–ºi. –û–¥–Ω–∞–∫, –±–∞–≥–∞—Ç–æ —Å—É—á–∞—Å–Ω–∏—Ö –∑–∞–≤–¥–∞–Ω—å –≤–∏–π—à–ª–∏ –∑–∞ —Ä–∞–º–∫–∏ –æ–±—á–∏—Å–ª–µ–Ω—å —á–µ—Ä–µ–∑ –æ–¥–∏–Ω
–æ—Å–Ω–æ–≤–Ω–∏–π –æ–±–º–µ–∂—É—é—á–∏–π —Ñ–∞–∫—Ç–æ—Ä: —Ç—Ä–∞–¥–∏—Üi–π–Ω–æ, –∫–æ–º–ø‚Äô—é—Ç–µ—Ä–∏ –º–æ–∂—É—Ç—å –¥–æ—Ç—Ä–∏–º—É–≤–∞—Ç–∏—Å—è –ª–∏—à–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏—Ö
–≤–∫–∞–∑i–≤–æ–∫/i–Ω—Å—Ç—Ä—É–∫—Üi–π, —è–∫i —ó–º –¥–∞—é—Ç—å.

–í–∏—Äi—à–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º –∑ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è –≤–∏–º–∞–≥–∞—î –Ω–∞–ø–∏—Å–∞–Ω–Ω—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏—Ö –ø–æ–∫—Ä–æ–∫–æ–≤–∏—Ö i–Ω—Å—Ç—Ä—É–∫—Üi–π, —è–∫i –º–∞—î –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ –∫–æ–º–ø‚Äô—é—Ç–µ—Ä. –ú–∏ –Ω–∞–∑–∏–≤–∞—î–º–æ —Üi –∫—Ä–æ–∫–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏. –£ —Ü—å–æ–º—É –≤–∏–ø–∞–¥–∫—É, –∫–æ–º–ø‚Äô—é—Ç–µ—Ä–∏ –º–æ–∂—É—Ç—å –¥–æ–ø–æ–º–æ–≥—Ç–∏ –Ω–∞–º
—Ç–∞–º, –¥–µ –º–∏:
1. –†–æ–∑—É–ºi—î–º–æ —è–∫ –≤–∏—Äi—à–∏—Ç–∏ –ø—Ä–æ–±–ª–µ–º—É.
2. –ú–æ–∂–µ–º–æ –æ–ø–∏—Å–∞—Ç–∏ –ø—Ä–æ–±–ª–µ–º—É –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —ái—Ç–∫–∏—Ö –ø–æ–∫—Ä–æ–∫–æ–≤–∏—Ö i–Ω—Å—Ç—Ä—É–∫—Üi–π, —è–∫i –∫–æ–º–ø‚Äô—é—Ç–µ—Ä –º–æ–∂–µ –∑—Ä–æ–∑—É–ºi—Ç–∏.

---


class: middle
count: false

# –ö–ª–∞—Å–∏—á–Ω–µ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω vs –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/mlVSprograming.png)]
]

???

–ú–µ—Ç–æ–¥–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è –¥–æ–∑–≤–æ–ª—è—é—Ç—å –∫–æ–º–ø‚Äô—é—Ç–µ—Ä–∞–º ‚Äú—É—á–∏—Ç–∏—Å—è‚Äù –Ω–∞ –ø—Ä–∏–∫–ª–∞–¥–∞—Ö. –í–∏—Äi—à–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º i–∑ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è –≤–∏–º–∞–≥–∞—î –≤–∏—è–≤–ª–µ–Ω–Ω—è –¥–µ—è–∫–æ–≥–æ —à–∞–±–ª–æ–Ω—É, –∞ –ø–æ—Çi–º, –∫–æ–ª–∏ —Ç–∞–∫–∏–π —à–∞–±–ª–æ–Ω –≥–æ—Ç–æ–≤–∏–π, –¥–æ–∑–≤–æ–ª—è—é—Ç—å, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –Ω–µ–π—Ä–æ–Ω–Ωi–π –º–µ—Ä–µ–∂i –≤–∏–≤—á–∏—Ç–∏ –∫–∞—Ä—Ç—É –ø–µ—Ä–µ—Ö–æ–¥i–≤ –ºi–∂ –≤—Öi–¥–Ω–∏–º–∏ —Ç–∞ –≤–∏—Öi–¥–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏. –¶—è –æ—Å–æ–±–ª–∏–≤i—Å—Ç—å –≤i–¥–∫—Ä–∏–≤–∞—î –Ω–æ–≤i —Ç–∏–ø–∏ –ø—Ä–æ–±–ª–µ–º, –¥–µ –∫–æ–º–ø‚Äô—é—Ç–µ—Ä–∏ –º–æ–∂—É—Ç—å –¥–æ–ø–æ–º–æ–≥—Ç–∏ –Ω–∞–º —É —ó—Ö —Ä–æ–∑–≤‚Äô—è–∑–∞–Ω–Ωi, –∑–∞ —É–º–æ–≤–∏, –∫–æ–ª–∏ –º–∏:
1. –í–∏–∑–Ω–∞—á–∏–ª–∏ —à–∞–±–ª–æ–Ω –ø—Ä–æ–±–ª–µ–º–∏.
2. –ú–∞—î–º–æ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö, —â–æ i–ª—é—Å—Ç—Ä—É—é—Ç—å —à–∞–±–ª–æ–Ω.
---

class: middle

# –¢–∏–ø–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

–ó–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–æ–º –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö (**–¥–æ—Å–≤i–¥—É**) –º–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è –ø–æ–¥i–ª—è—é—Ç—å –Ω–∞ —á–æ—Ç–∏—Ä–∏ —Ç–∏–ø–∏: –∫–æ–Ω—Ç—Ä–æ–ª—å–æ–≤–∞–Ω–µ (–∑ —É—á–∏—Ç–µ–ª–µ–º), –Ω–∞–øi–≤–∫–æ–Ω—Ç—Ä–æ–ª—å–æ–≤–∞–Ω–µ, –Ω–µ–∫–æ–Ω—Ç—Ä–æ–ª—å–æ–≤–∞–Ω–µ (–±–µ–∑ —É—á–∏—Ç–µ–ª—è) —Ç–∞ –∑ –øi–¥–∫—Äi–ø–ª–µ–Ω–Ω—è–º.

.center[
.width-100[![](figures/lec1/types1.png)]
]

---

class: middle
count: false

# –¢–∏–ø–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/types2.png)]
]

---

class: middle
count: false

# –¢–∏–ø–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/types3.png)]
]

---

class: middle
count: false

# –¢–∏–ø–∏ –Ω–∞–≤—á–∞–Ω–Ω—è

.center[
.width-100[![](figures/lec1/types4.png)]
]

---

class: middle

# –Ø–∫ –≤—á–∏—Ç—å—Å—è –ª—é–¥–∏–Ω–∞?

- –ú–∏ —Ç–∞ —ñ–Ω—à—ñ —Ä–æ–∑—É–º–Ω—ñ —ñ—Å—Ç–æ—Ç–∏, –≤—á–∏–º–æ—Å—å –∑–∞–≤–¥—è–∫–∏ **–≤–∑–∞—î–º–æ–¥—ñ—ó —ñ–∑ —Å–≤–æ—ó–º –æ—Ç–æ—á–µ–Ω–Ω—è–º**

- –í–∑–∞—î–º–æ–¥—ñ—ó —á–∞—Å—Ç–æ –±—É–≤–∞—é—Ç—å **–ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∏–º–∏** - –º–∞–π–±—É—Ç–Ω—ñ –≤–∑–∞—î–º–æ–¥—ñ—ó –º–æ–∂—É—Ç—å –∑–∞–ª–µ–∂–∞—Ç–∏ –≤—ñ–¥ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö

- –ú–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω—ñ –Ω–∞ **—Ä–µ–∑—É–ª—å—Ç–∞—Ç**

- –ú–∏ –º–æ–∂–µ–º–æ –≤—á–∏—Ç–∏—Å—è **–Ω–µ –º–∞—é—á–∏ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤** –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—ó –ø–æ–≤–µ–¥—ñ–Ω–∫–∏


???

–ù–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ, –ø—Ä–µ–∫—Ä–∞—Å–Ω–∞ –±—ñ–æ–ª–æ–≥—ñ—á–Ω–æ –Ω–∞—Ç—Ö–Ω–µ–Ω–Ω–∞ –ø–∞—Ä–∞–¥–∏–≥–º–∞ –ø—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è, —è–∫–∞ –¥–æ–∑–≤–æ–ª—è—î –∫–æ–º–ø‚Äô—é—Ç–µ—Ä—É –Ω–∞–≤—á–∞—Ç–∏—Å—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–∞–Ω–∏—Ö —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω—å

---

class: middle

# –ú–æ–∑–æ–∫ –ª—é–¥–∏–Ω–∏

–ë–∞–∑–æ–≤–æ—é –æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω–æ—é –æ–¥–∏–Ω–∏—Ü–µ—é –º–æ–∑–∫—É —î –Ω–µ–π—Ä–æ–Ω. –ú–æ–∑–æ–∫ –¥–æ—Ä–æ—Å–ª–æ—ó –ª—é–¥–∏–Ω–∏ —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è –∑ $86$ –ºi–ª—å—è—Ä–¥i–≤ –Ω–µ–π—Ä–æ–Ωi–≤, —è–∫i –∑‚Äô—î–¥–Ω–∞–Ωi –º—ñ–∂ —Å–æ–±–æ—é –ø—Ä–∏–±–ª–∏–∑–Ω–æ
$10^{14}$ ‚àí $10^{15}$ —Å–∏–Ω–∞–ø—Å–∞–º–∏.

.footnote[–î–∂–µ—Ä–µ–ª–æ: [F. A. Azevedo —Ç–∞ —ñ–Ω.](https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.21974), 2009.]

---

class: middle

# –ë—ñ–æ–ª–æ–≥—ñ—á–Ω–∏–π —Ç–∞ —à—Ç—É—á–Ω–∏–π –Ω–µ–π—Ä–æ–Ω

.center[
.width-100[![](figures/lec1/NeuronBioMathModels.png)]
]

---

class: middle,
# –î–µ—è–∫—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó

.center[
.width-100[![](figures/lec1/actFunctions.png)]
]

---


class: middle

# –õ—é–¥–∏–Ω–∞ –¥–æ–±—Ä–µ —Å–ø—Ä–∏–π–º–∞—Ç–∏ –≤—ñ–∑—É–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é

---

class: middle, center

.width-100[![](figures/lec1/mushrooms.png)]

–©–æ –í–∏ –±–∞—á–∏—Ç–µ?

???

.italic[–Ø–∫ –í–∏ —Ü–µ —Ä–æ–±–∏—Ç–µ?]

---

class: middle

.center[
.width-70[![](figures/lec1/dog1.jpg)]

–°–æ–±–∞–∫–∞-–≤—ñ–≤—Ü—è —á–∏ —à–≤–∞–±—Ä–∞?
]


---


class: middle

–õ—é–¥—Å—å–∫–∏–π –º–æ–∑–æ–∫ –Ω–∞—Å—Ç—ñ–ª—å–∫–∏ –¥–æ–±—Ä–µ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç—É—î –≤—ñ–∑—É–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é, —â–æ **—Ä–æ–∑—Ä–∏–≤** –º—ñ–∂ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º —Ç–∞ –π–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ—é —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—î—é (–ø—ñ–∫—Å–µ–ª—è–º–∏) –≤–∞–∂–∫–æ –æ—Ü—ñ–Ω–∏—Ç–∏ —ñ–Ω—Ç—É—ó—Ç–∏–≤–Ω–æ: 

<br>
.center[
![](figures/lec1/mushroom-small.png)

–¶–µ –º—É—Ö–æ–º–æ—Ä.
]

---

class: middle, center

.width-70[![](figures/lec1/mushroom-big.png)]

–¶–µ –º—É—Ö–æ–º–æ—Ä.

---

class: middle, center

.width-30[![](figures/lec1/mushroom-rgb0.png)] +
.width-30[![](figures/lec1/mushroom-rgb1.png)] +
.width-30[![](figures/lec1/mushroom-rgb2.png)]


–¶–µ –º—É—Ö–æ–º–æ—Ä.

---

class: middle, center

.width-80[![](figures/lec1/mushroom-small-nb.png)]

–¶–µ –º—É—Ö–æ–º–æ—Ä.

---

class: middle, center

# –Ø–∫ –Ω–∞–≤—á–∏—Ç—å –º–∞—à–∏–Ω –±–∞—á–∏—Ç–∏?

---

class: middle

.center.width-60[![](figures/lec1/cat1.png)]

---

count: false
class: black-slide

.center.width-60[![](figures/lec1/cat2.png)]

---

count: false
class: black-slide, middle

.center.width-80[![](figures/lec1/cat3.png)]

---

count: false
class: black-slide, middle

.center.width-80[![](figures/lec1/cat4.png)]

---

class: middle

–î–ª—è –ø–æ—à—É–∫—É —à–∞–±–ª–æ–Ω—É –≤ –¥–∞–Ω–∏—Ö (–≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó, –æ–∑–Ω–∞–∫) –ø–æ—Ç—Ä—ñ–±–Ω–∞ –ø–æ–±—É–¥–æ–≤–∞ **—Å–∫–ª–∞–¥–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π**, —è–∫—ñ –± –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤—Ä—É—á–Ω—É –±—É–ª–æ –± –¥—É–∂–µ —Å–∫–ª–∞–¥–Ω–æ.

–û–¥–Ω–∞–∫, –º–æ–∂–Ω–∞ –Ω–∞–ø–∏—Å–∞—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º—É, —è–∫–∞ –±—É–¥–µ **–≤—á–∏—Ç–∏—Å—å** –∑–Ω–∞—Ö–æ–¥–∏—Ç–∏ —à–∞–±–ª–æ–Ω –≤ –¥–∞–Ω–∏—Ö —Å–∞–º–æ—Å—Ç—ñ–π–Ω–æ. 

---

class: middle

.center.width-100[![](figures/lec1/deepL.jpg)]

---

class: middle

# –©–æ –≤—Ö–æ–¥–∏—Ç—å –¥–æ –∑–∞–¥–∞—á—ñ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è?

- –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–±–ª–µ–º–∏ + –¥–∞–Ω—ñ
- –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
- –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç
- –í–∏–±—ñ—Ä –∞–ª–≥–æ—Ä–∏—Ç–º—É –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó

---

class: middle

# –Ø–∫—ñ –¥–∞–Ω—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è?

.center.width-100[![](figures/lec1/inp3.png)]

---

class: middle

# –û–∑–Ω–∞–∫–∏ —É –º–∞—à–∏–Ω–Ω–æ–º—É –Ω–∞–≤—á–∞–Ω–Ω—ñ

–û–∑–Ω–∞–∫–∏ - —Ü–µ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è, —è–∫—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –¥–ª—è –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å –º–æ–¥–µ–ª–ª—é.

- –î–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω—å **–∫–æ–∂–µ–Ω** –ø—ñ–∫—Å–µ–ª—å —î –æ–∑–Ω–∞–∫–æ—é
- –î–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å—É, **—á–∞—Å—Ç–æ—Ç–∞** —Ç–∞ **–≥—É—á–Ω—ñ—Å—Ç—å** —î –æ–∑–Ω–∞–∫–∞–º–∏
- –î–ª—è –±–µ–∑–ø—ñ–ª–æ—Ç–Ω–∏—Ö –∞–≤—Ç–æ–º–æ–±—ñ–ª—ñ–≤ –¥–∞–Ω—ñ –∑ **–∫–∞–º–µ—Ä**, **—Ä–∞–¥–∞—Ä—ñ–≤** —ñ **GPS** —î –æ–∑–Ω–∞–∫–∞–º–∏

---

class: middle

# –¢–∏–ø–∏ –æ–∑–Ω–∞–∫ —É —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω—ñ—Ü—ñ

- –ü—ñ–∫—Å–µ–ª—ñ (RGB –¥–∞–Ω—ñ)
- –ì–ª–∏–±–∏–Ω–∞ (—Å–æ–Ω–∞—Ä, –ª–∞–∑–µ—Ä–Ω—ñ –¥–∞–ª–µ–∫–æ–º—ñ—Ä–∏)
- –û—Ä—ñ—î–Ω—Ç–∞—Ü—ñ—è –∞–±–æ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è (–≥—ñ—Ä–æ—Å–∫–æ–ø, –∞–∫—Å–µ–ª–µ—Ä–æ–º–µ—Ç—Ä, –∫–æ–º–ø–∞—Å)

---

class: middle

# –ù–µ–¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è vs –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è

.center.width-100[![](figures/lec1/Regularization.png)]

---

class: middle
count: false

# –ù–µ–¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è vs –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è

.center.width-80[![](figures/lec1/fittings.jpg)]

---


class: middle

# –©–æ —Ç–∞–∫–µ –º–æ–¥–µ–ª—å?

–•–æ—á–∞ —Ç–µ, —â–æ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤—Å–µ—Ä–µ–¥–∏–Ωi –≥–ª–∏–±–∏–Ω–Ω–æ—ó –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂i, –º–æ–∂–µ –±—É—Ç–∏ —Å–∫–ª–∞–¥–Ω–∏–º, –∑–∞ —Å–≤–æ—î—é —Å—É—Ç—Ç—é —Ü–µ –ø—Ä–æ—Å—Ç–æ —Ñ—É–Ω–∫—Üi—ó. –í–æ–Ω–∏ –±–µ—Ä—É—Ç—å –ø–µ–≤–Ωi –≤—Öi–¥–Ωi –¥–∞–Ωi: **INPUT x** i
–≥–µ–Ω–µ—Ä—É—é—Ç—å –¥–µ—è–∫i –≤–∏—Öi–¥–Ωi –¥–∞–Ωi: **OUTPUT f(x)**

.center.width-30[![](figures/lec1/func.png)]

---


# –ó —á–æ–≥–æ —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è –º–æ–¥–µ–ª—å?

.center.width-100[![](figures/lec1/compon.png)]

---

# –î–∂–µ—Ä–µ–ª–∞ –ø–æ–º–∏–ª–æ–∫ –º–æ–¥–µ–ª—ñ

- –ó—Å—É–≤  (Bias)
- –†–æ–∑–∫–∏–¥ (Variance)
- –®—É–º (Irreducible error)

$$Err = Bias^2 + Variance + Irreducible error$$

.center.width-70[![](figures/lec1/biasvariance.png)]

---

# –Ü–Ω—Ç—É—ó—Ü—ñ—è

<br><br>
.center.width-55[![](figures/lec1/bias-and-variance.jpg)]

---

class: blue-slide, middle, center
count: false

.larger-xx[–û–±–ª—Å—Ç—ñ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ç–∞ —É—Å–ø—ñ—Ö–∏ –®–Ü]

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/5kpsZoKjPgQ" frameborder="0" allowfullscreen></iframe>

Object detection, pose estimation, segmentation (2019)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/V1eYniJ0Rnk" frameborder="0" allowfullscreen></iframe>

Reinforcement learning (Mnih et al, 2014)

---


class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/qhUvQiKec2U" frameborder="0" allowfullscreen></iframe>

Autonomous cars (NVIDIA, 2016)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/tlThdr3O5Qo" frameborder="0" allowfullscreen></iframe>

Autopilot (Tesla, 2019)

???

A full build of Autopilot neural networks involves 48 networks that take 70,000 GPU hours to train üî•. Together, they output 1,000 distinct tensors (predictions) at each timestep.

---


class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/hA_-MkU0Nfw" frameborder="0" allowfullscreen></iframe>

Autonomous cars (Waymo, 2022)

---

class: middle, black-slide

.center[
<video loop controls preload="auto" height="400" width="600">
  <source src="./figures/lec1/physics-simulation.mp4" type="video/mp4">
</video>

Physics simulation (Sanchez-Gonzalez et al, 2020)

]

---

class: middle, black-slide, center

<iframe width="600" height="450" src="https://www.youtube.com/embed/gg7WjuFs8F4" frameborder="0" allowfullscreen></iframe>

AI for Science (Deepmind, AlphaFold, 2020)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/7gh6_U7Nfjs" frameborder="0" allowfullscreen></iframe>

Speech synthesis and question answering (Google, 2018)

---


class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/kSLJriaOumA" frameborder="0" allowfullscreen></iframe>

Image generation (Karras et al, 2018)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/qTgPSKKjfVg" frameborder="0" allowfullscreen></iframe>

Image generation and AI art (OpenAI, 2022)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/J_2fIGmsoRg" frameborder="0" allowfullscreen></iframe>

Reface –æ–∂–∏–≤–∏–≤ –≤—ñ–¥–æ–º—ñ –∫–∏—ó–≤—Å—å–∫—ñ –º—É—Ä–∞–ª–∏ –¥–æ –î–Ω—è –ö–∏—î–≤–∞ (2021)

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/Zm9B-DvwOgw" frameborder="0" allowfullscreen></iframe>

Write computer code (OpenAI, 2021)

---

class: middle, center, black-slide

.center.width-100[![](figures/lec1/ChatGPT.png)]

–í—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏ –Ω–∞ –≤—Å—ñ –≤–∞—à—ñ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è (OpenAI, 2022)

---

class: middle, center

.width-70[![](figures/lec1/turing-award.png)]

.italic[ –ê—Å–æ—Ü—ñ–∞—Ü—ñ—î—é –æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω–æ—ó —Ç–µ—Ö–Ω—ñ–∫–∏ (ACM) –Ω–∞–≥–æ—Ä–æ–¥–∂–µ–Ω–æ –≤ 2018 —Ä–æ—Ü—ñ –ø—Ä–µ–º—ñ—î—é –¢—é—Ä—ñ–Ω–≥–∞ —Ç–∞–∫–∏—Ö –Ω–∞—É–∫–æ–≤—Ü—ñ–≤: .bold[Yann LeCun], .bold[Geoffrey Hinton], .bold[Yoshua Bengio]  –∑–∞ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ñ —Ç–∞ —ñ–Ω–∂–µ–Ω–µ—Ä–Ω—ñ –ø—Ä–æ—Ä–∏–≤–∏, —è–∫—ñ –∑—Ä–æ–±–ª–∏ –≤ –≥–ª–∏–±–∏–Ω–Ω–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂–∞—Ö.]

---

# –ß–æ–º—É DL –ø—Ä–∞—Ü—é—î?

.center.grid[
.kol-1-2[
–ê–ª–≥–æ—Ä–∏—Ç–º–∏ (—Å—Ç–∞—Ä—ñ —Ç–∞ –Ω–æ–≤—ñ)<br><br>
.width-90[![](figures/lec1/skip-connection.png)]
]
.center.kol-1-2[
–ó—Ä–æ—Å—Ç–∞—î –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö<br><br>
.width-50[![](figures/lec1/imagenet.jpeg)]
]
]

.center.grid[
.kol-1-2[
–ü—Ä–æ–≥—Ä–∞–º–Ω–µ –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è<br>
.width-90[![](figures/lec1/software.png)]
]
.kol-1-2[
–ë—ñ–ª—å—à —à–≤–∏–¥–∫—ñ –æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω—ñ –º–∞—à–∏–Ω–∏ <br><br>
.width-50[![](figures/lec1/titan.jpg)]
]
]

???

–£—Å–ø—ñ—Ö –≥–ª–∏–±–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è —î –±–∞–≥–∞—Ç–æ—Ñ–∞–∫—Ç–æ—Ä–Ω–∏–º ...

---

class: middle

## DL —è–∫ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–Ω–∞ –º–æ–≤–∞

.width-100[![](figures/lec1/lego-composition.png)]

.footnote[Image source: [http://chelseamarzean.com/post-the-atomic-workflow/](http://chelseamarzean.com/post-the-atomic-workflow/), 2016.]

---



class: middle

.center.circle.width-30[![](figures/lec1/bishop.jpg)]

.italic["For the last forty years we have programmed computers; for the next forty years we will train them."]

.pull-right[Chris Bishop, 2020.]

???
–ö—Ä—ñ—Å—Ç–æ—Ñ–µ—Ä –ë—ñ—à–æ–ø —î —Ç–µ—Ö–Ω—ñ—á–Ω–∏–º —Å–ø—ñ–≤—Ä–æ–±—ñ—Ç–Ω–∏–∫–æ–º Microsoft —ñ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º Microsoft Research AI4Science. –í—ñ–Ω —Ç–∞–∫–æ–∂ —î –ø–æ—á–µ—Å–Ω–∏–º –ø—Ä–æ—Ñ–µ—Å–æ—Ä–æ–º –∫–æ–º–ø‚Äô—é—Ç–µ—Ä–Ω–∏—Ö –Ω–∞—É–∫ –ï–¥–∏–Ω–±—É—Ä–∑—å–∫–æ–≥–æ —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç—É —Ç–∞ —á–ª–µ–Ω–æ–º –î–∞—Ä–≤—ñ–Ω—ñ–≤—Å—å–∫–æ–≥–æ –∫–æ–ª–µ–¥–∂—É –≤ –ö–µ–º–±—Ä–∏–¥–∂—ñ. –£ 2017 —Ä–æ—Ü—ñ –≤—ñ–Ω –±—É–≤ –æ–±—Ä–∞–Ω–∏–π —á–ª–µ–Ω–æ–º –ö–æ—Ä–æ–ª—ñ–≤—Å—å–∫–æ–≥–æ —Ç–æ–≤–∞—Ä–∏—Å—Ç–≤–∞.

---

class: middle

# –í–∏–∫–ª–∏–∫–∏ –®–Ü


–û—Å–Ω–æ–≤–Ω–∏–º –≤–∏–∫–ª–∏–∫–æ–º —à—Ç—É—á–Ω–æ–≥–æ —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É —Ç–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è —î –ø—Ä–∏–π–Ω—è—Ç—Ç—è –ø—Ä–∞–≤–∏–ª—å–Ω–∏—Ö —Ä—ñ—à–µ–Ω—å –≤ —É–º–æ–≤–∞—Ö **–Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ—Å—Ç—ñ**

---

class: blue-slide, middle, center
count: false

.larger-xx[–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω]

–û–¥–Ω–æ—à–∞—Ä–æ–≤–∞ –Ω–µ–π—Ä–æ–Ω–Ω–∞ –º–µ—Ä–µ–∂–∞

–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω vs –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è

---

# –ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω

–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω (Rosenblatt, 1958)

$$g(z) = \begin{cases}
   1 &\text{if } z =\sum_i w_i x_i + b \geq 0  \\\\
   0 &\text{otherwise}
\end{cases}$$

–¶—è –º–æ–¥–µ–ª—å —Å–ø–æ—á–∞—Ç–∫—É –±—É–ª–∞ –º–æ—Ç–∏–≤–æ–≤–∞–Ω–∞ –±—ñ–æ–ª–æ–≥—ñ—î—é, –¥–µ $w_i$ &mdash; —Ü–µ —Å–∏–Ω–∞–ø—Ç–∏—á–Ω—ñ –≤–∞–≥–∏ –¥–ª—è –≤—Ö—ñ–¥–Ω–∏—Ö —Å–∏–≥–Ω–∞–ª—ñ–≤ $x_i$ —Ç–∞  $g$ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó.
.center.width-65[![](figures/lec1/perceptron.jpg)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Frank Rosenblatt, [Mark I Perceptron operators' manual](https://apps.dtic.mil/sti/pdfs/AD0236965.pdf), 1960.]

???

–£ –ª–∏—Å—Ç–æ–ø–∞–¥—ñ 1958 —Ä–æ–∫—É –§—Ä–µ–Ω–∫ –†–æ–∑–µ–Ω–±–ª–∞—Ç—Ç –≤–∏–Ω–∞–π—à–æ–≤ –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω, –∞–±–æ Mark I, —É –ö–æ—Ä–Ω–µ–ª—å—Å—å–∫–æ–º—É —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç—ñ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–π —É 1960 —Ä–æ—Ü—ñ, —Ü–µ –±—É–≤ –ø–µ—Ä—à–∏–π –∫–æ–º–ø‚Äô—é—Ç–µ—Ä, —è–∫–∏–π –º—ñ–≥ –≤–∏–≤—á–∞—Ç–∏ –Ω–æ–≤—ñ –Ω–∞–≤–∏—á–∫–∏ –º–µ—Ç–æ–¥–æ–º –ø—Ä–æ–± —ñ –ø–æ–º–∏–ª–æ–∫, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —Ç–∏–ø –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂—ñ, —è–∫–∞ —Å–∏–º—É–ª—é–≤–∞–ª–∞ –ø—Ä–æ—Ü–µ—Å–∏ –º–∏—Å–ª–µ–Ω–Ω—è –ª—é–¥–∏–Ω–∏.

---

class: middle

.center[
.width-70[![](figures/lec1/neuron.png)]
]

.smaller-xx[
$$
\begin{aligned}
\mathbf{X} = \begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
\vdots \\\\
x\_m
\end{bmatrix} 
&&
\mathbf{W} = \begin{bmatrix}
w\_1  \\\\
w\_2  \\\\
\vdots \\\\
w\_m
\end{bmatrix}
&& 
\mathbf{X}^T = \begin{bmatrix}
x\_1 & x\_2 & \cdots & x\_m
\end{bmatrix} 
\end{aligned}$$


$$\boxed{\begin{aligned}z &= \sum\_{n=1}^{m} w\_n x\_n + b = \mathbf{X}^T \cdot \mathbf{W} + b = \mathbf{W}^T \cdot \mathbf{X} + b \\\\
\hat y &= g(z) \\\\
\mathcal{L}(\hat y, y) &= - \frac{1}{n} \sum\_{i=1}^{n} \big(y^{(i)} \log(\hat y^{(i)}) + (1- y^{(i)}) \log(1 -\hat y^{(i)}) \big)
\end{aligned}}$$

]

---

class: middle

.center[
.width-80[![](figures/lec1/neuron.png)]
]

.smaller-xx[

.center[*–ü—Ä—è–º–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è*]

$$\boxed{\begin{aligned}z &= \sum\_{n=1}^{m} w\_n x\_n + b = \mathbf{X}^T \cdot \mathbf{W} + b = \mathbf{W}^T \cdot \mathbf{X} + b \\\\
\hat y &= g(z) \\\\
\mathcal{L}(\hat y, y) &= - \frac{1}{n} \sum\_{i=1}^{n} \big(y^{(i)} \log(\hat y^{(i)}) + (1- y^{(i)}) \log(1 -\hat y^{(i)}) \big)
\end{aligned}}$$

]

---


class: middle

## –ü—Ä–∏–∫–ª–∞–¥

–ü—Ä–∏–ø—É—Å—Ç–∏–º–æ $m = 3$

$$
\begin{aligned}
\mathbf{X} = \begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
x\_3
\end{bmatrix} = \begin{bmatrix}
-0.1  \\\\
0.7  \\\\
0.5
\end{bmatrix} 
&&
\mathbf{W} = \begin{bmatrix}
w\_1  \\\\
w\_2  \\\\
w\_3
\end{bmatrix} =
\begin{bmatrix}
1  \\\\
-2  \\\\
2
\end{bmatrix}
&&
b = 0.8
\end{aligned}$$

$$\boxed{\begin{aligned}
z = \sum_{n=1}^{3} w_n x_n + b &= w_1 x_1 + w_2 x_2 + w_3 x_3 + b = \\\\
&= 1 \cdot -0.1 + -2 \cdot 0.7 + 2 \cdot 0.5 + 0.8 = 0.3
\end{aligned}}$$

$$\boxed{\begin{aligned}
z = \mathbf{X}^T \cdot \mathbf{W} + b &= \begin{bmatrix}
x\_1 & x\_2 &  x\_3 
\end{bmatrix} \begin{bmatrix}
w\_1  \\\\
w\_2  \\\\
w\_3
\end{bmatrix} + b = \\\\
&= w_1 x_1 + w_2 x_2 + w_3 x_3 + b = 0.3
\end{aligned}}$$

$$\hat y  = g(z) = g(\mathbf{X}^T \cdot \mathbf{W} + b) = \frac{1}{1 + \exp(-z)} = \frac{1}{1 + \exp(-0.3)} \approx 0.57 $$

---


class: blue-slide, middle, center
count: false

.larger-xx[–û–¥–Ω–æ–≤–∏–º—ñ—Ä–Ω–∏–π –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π —Å–ø—É—Å–∫]

---


class: middle

## –û–¥–Ω–æ–≤–∏–º—ñ—Ä–Ω–∏–π –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π —Å–ø—É—Å–∫
.smaller-x[

–†–æ–∑–≥–ª—è–Ω–µ–º–æ –¥–µ—è–∫—É –Ω–µ–ø–µ—Ä–µ—Ä–≤–Ω—É, –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ–π–æ–≤–∞–Ω—É  —Ñ—É–Ω–∫—Ü—ñ—é $f: \mathbb{R} \rightarrow \mathbb{R}$. –†–æ–∑–∫–ª–∞–≤—à–∏ –≤ —Ä—è–¥ –¢–µ–π–ª–æ—Ä–∞, –º–∏ –æ—Ç—Ä–∏–º—É—î–º–æ:

$$f(x + \varepsilon) = f(x) + \varepsilon f^{'}(x) + \mathcal{O}(\varepsilon^2)$$

–î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏ –¥–∞–≤–∞–π—Ç–µ –≤–∏–±–µ—Ä–µ–º–æ —Ñ—ñ–∫—Å–æ–≤–∞–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –∫—Ä–æ–∫—É $\alpha > 0$ —Ç–∞ –æ–±–µ—Ä–µ–º–æ $\varepsilon = -\alpha f^{'}(x)$. –ü—ñ–¥—Å—Ç–∞–≤–∏–≤—à–∏ —Ü–µ —É –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –≤–∏—Ä–∞–∑:

$$f(x -\alpha f^{'}(x)) = f(x) - \alpha f^{'2}(x)  + \mathcal{O}(\alpha^2 f^{'2}(x))$$

–Ø–∫—â–æ –ø–æ—Ö—ñ–¥–Ω–∞ $f^{'}(x) \neq 0$ –Ω–µ –∑–Ω–∏–∫–∞—î, –º–∏ —Ä–æ–±–∏–º–æ –ø—Ä–æ–≥—Ä–µ—Å, –æ—Å–∫—ñ–ª—å–∫–∏ $\alpha f^{'2}(x) > 0$. –ö—Ä—ñ–º —Ç–æ–≥–æ, –º–∏ –∑–∞–≤–∂–¥–∏ –º–æ–∂–µ–º–æ –≤–∏–±—Ä–∞—Ç–∏ $\alpha$ –¥–æ—Å–∏—Ç—å –º–∞–ª–∏–º, —â–æ–± –≤–∏—Ä–∞–∑–∏ –≤–∏—â–æ–≥–æ –ø–æ—Ä—è–¥–∫—É –∑–∞–Ω—É–ª–∏—Ç–∏. –¢–æ–º—É –º–∏ –ø—Ä–∏—Ö–æ–¥–∏–º–æ –¥–æ

$$f(x -\alpha f^{'}(x)) \lessapprox f(x)$$

–¶–µ –æ–∑–Ω–∞—á–∞—î, —â–æ —è–∫—â–æ –º–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ:

$$x \leftarrow x -\alpha f^{'}(x)$$

–¥–ª—è —ñ—Ç–µ—Ä–∞—Ü—ñ—ó –ø–æ $x$, –∑–Ω–∞—á–µ–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó $f(x)$  –º–æ–∂–µ –∑–º–µ–Ω—à–∏—Ç–∏—Å—å. 
]

???
Gradient descent in one dimension is an excellent example to explain why the gradient descent algorithm may reduce the value of the objective function.

The Taylor series is used to describe what the function looks like in the neighborhood of some poin $x$.

That is, in first-order approximation $f(x + \varepsilon)$  is given by the function value $f(x)$ and the first derivative $f^{'}(x)$ at $x$. It is not unreasonable to assume that for small $\varepsilon$ moving in the direction of the negative gradient will decrease $f$. 

Therefore, in gradient descent we first choose an initial value $x$ and a constant $\alpha > 0$ and then use them to continuously iterate $x$ until the stop condition is reached, for example, when the magnitude of the gradient $|f^{'}(x)|$ is small enough or the number of iterations has reached a certain value.

---

class: middle

.center[
.width-80[![](figures/lec1/gdC.png)]
]

???

For simplicity we choose the objective function $f(x) = x^2$ to illustrate how to implement gradient descent. Although we know that $x = 0$ is the solution to minimize $f(x)$, we still use this simple function to observe how $x$ changes.

---

class: middle

–•—ñ–¥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –∑–∞ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ $x$ 

.center[
.width-80[![](figures/lec1/gd025.png)]
]

---

class: middle

–•—ñ–¥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –∑–∞ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ $x$ 

.center[
.width-80[![](figures/lec1/gd006.png)]
]

???
If we use a learning rate that is too small, it will cause $x$ to update very slowly, requiring more iterations to get a better solution.

---

lass: middle

–•—ñ–¥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –∑–∞ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ $x$ 

.center[
.width-80[![](figures/lec1/gd1.1.png)]
]

???
if we use an excessively high learning rate, $|\alpha f^{'}(x)|$ might be too large for the first-order Taylor expansion formula. That is, the term $\mathcal{O}(\alpha^2 f^{'2}(x))$ might become significant. In this case, we cannot guarantee that the iteration of $x$ will be able to lower the value of $f(x)$.

---

class: blue-slide, middle, center
count: false

.larger-xx[–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω: –ó–≤–æ—Ä–æ—Ç–Ω–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è]

---

class: middle

–£ –ø–æ–∑–Ω–∞—á–µ–Ω–Ω—è—Ö –õ–µ–π–±–Ω—ñ—Ü–∞ **–ø—Ä–∞–≤–∏–ª–æ –ª–∞–Ω—Ü—é–∂–∫–∞** —Å—Ç–≤–µ—Ä–¥–∂—É—î, —â–æ
$$
\begin{aligned}
\frac{\partial \ell}{\partial \theta\_i} &= \sum\_{k \in \text{parents}(\ell)} \frac{\partial \ell}{\partial u\_k} \underbrace{\frac{\partial u\_k}{\partial \theta\_i}}\_{\text{recursive case}}
\end{aligned}$$

---

class: middle

## –ó–≤–æ—Ä–æ—Ç–Ω–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è

- –û—Å–∫—ñ–ª—å–∫–∏ –Ω–µ–π—Ä–æ–Ω–Ω–∞ –º–µ—Ä–µ–∂–∞ —î **–∫–æ–º–ø–æ–∑–∏—Ü—ñ—î—é –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ–π–æ–≤–∞–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π**, –∑–∞–≥–∞–ª—å–Ω—ñ –ø–æ—Ö—ñ–¥–Ω—ñ –≤—Ç—Ä–∞—Ç –º–æ–∂–Ω–∞ –æ—Ü—ñ–Ω–∏—Ç–∏ –∑–≤–æ—Ä–æ—Ç–Ω–æ, –∑–∞—Å—Ç–æ—Å–æ–≤—É—é—á–∏ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–∞–≤–∏–ª–æ –ª–∞–Ω—Ü—é–∂–∫–∞ –¥–æ —ó—ó –æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω–æ–≥–æ –≥—Ä–∞—Ñ—É.
- –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ü—ñ—î—ó –ø—Ä–æ—Ü–µ–¥—É—Ä–∏ –Ω–∞–∑–∏–≤–∞—î—Ç—å—Å—è –∑–≤–æ—Ä–æ—Ç–Ω–∏–º *–∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –¥–∏—Ñ–µ—Ä–µ–Ω—Ü—ñ—é–≤–∞–Ω–Ω—è–º* –∞–±–æ **–∑–≤–æ—Ä–æ—Ç–Ω–∏–º –ø–æ—à–∏—Ä–µ–Ω–Ω—è–º**.

---

class: middle



.smaller-xx[

.center[*–ü—Ä—è–º–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è*]

$$\boxed{\begin{aligned}z &= \sum\_{n=1}^{m} w\_n x\_n + b = \mathbf{X}^T \cdot \mathbf{W} + b = \mathbf{W}^T \cdot \mathbf{X} + b \\\\
\hat y &= g(z) = \sigma(z) = \frac{1}{1 + \exp(-z)} \\\\
\mathcal{L}(\hat y, y) &= - \frac{1}{n} \sum\_{i=1}^{n} \big(y^{(i)} \log(\hat y^{(i)}) + (1- y^{(i)}) \log(1 -\hat y^{(i)}) \big)
\end{aligned}}$$


.grid[
.kol-2-3[

.center[*–ó–≤–æ—Ä–æ—Ç–Ω–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è*]

$$\boxed{\begin{aligned}
\frac{\partial \mathcal{L}(\hat y, y)}{\partial \hat y} &= -\frac{y}{\hat y} + \frac{1- y}{1 - \hat y} \\\\[18pt]
\frac{\partial \mathcal{L}(\hat y, y)}{\partial z} &= \frac{\partial \mathcal{L}(\hat y, y)}{\partial \hat y} \frac{\partial \hat y}{\partial z} = \hat y - y \\\\[18pt]
\frac{\partial \mathcal{L}(\hat y, y)}{\partial \mathbf{W}} &= \frac{\partial \mathcal{L}(\hat y, y)}{\partial \hat y} \frac{\partial \hat y}{\partial z} \frac{\partial z}{\partial \mathbf{W}} = \mathbf{X}^T \cdot (\hat y - y) \\\\[18pt]
\frac{\partial \mathcal{L}(\hat y, y)}{\partial b} &=  \frac{\partial \mathcal{L}(\hat y, y)}{\partial \hat y} \frac{\partial \hat y}{\partial z} \frac{\partial z}{\partial b} = \hat y - y
\end{aligned}}$$
]

.kol-1-3[
.center[*–û–Ω–æ–≤–ª–µ–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤*]

$$\boxed{\begin{aligned}
\mathbf{W} &= \mathbf{W} - \alpha \frac{\partial \mathcal{L}(\hat y, y)}{\partial \mathbf{W}} \\\\[18pt]
b &= b - \alpha \frac{\partial \mathcal{L}(\hat y, y)}{\partial b}
\end{aligned}}$$
]]
]

---

class: blue-slide, middle, center
count: false

.larger-xx[–ü–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω –∑ –±–∞–≥–∞—Ç—å–º–∞ –≤–∏—Ö–æ–¥–∞–º–∏]

---

class: middle

# Multi Output Perceptron

.smaller-x[–û—Å–∫—ñ–ª—å–∫–∏ –≤—Å—ñ –≤—Ö–æ–¥–∏ —â—ñ–ª—å–Ω–æ –∑‚Äô—î–¥–Ω–∞–Ω—ñ –∑ —É—Å—ñ–º–∞ –≤–∏—Ö–æ–¥–∞–º–∏, —Ü—ñ —à–∞—Ä–∏ –Ω–∞–∑–∏–≤–∞—é—Ç—å—Å—è *Dense*]

.center[
.width-70[![](figures/lec1/multiOuptup.png)]
]

$$z\_j = \sum\_{n=1}^{m} w\_{j, n} x\_n  + b\_j$$

---

class: middle

## Example

.center[
.width-50[![](figures/lec1/multiOuptup.png)]
]
.smaller-xx[
$$\begin{aligned}
\mathbf{X}^{m \times 1} = \begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
\vdots \\\\
x\_m
\end{bmatrix} 
&&
\mathbf{W}^{3 \times m} = \begin{bmatrix}
w\_{11} & w\_{12} &  \cdots & w\_{1m} \\\\
w\_{21} & w\_{22} & \cdots & w\_{2m} \\\\
w\_{31} & w\_{32} & \cdots & w\_{3m}
\end{bmatrix}
&& 
\mathbf{b}^{3 \times 1} = \begin{bmatrix}
b\_1 \\\\
b\_2 \\\\
b\_3
\end{bmatrix}
\end{aligned}$$

$$\boxed{\begin{aligned}
\mathbf{z} =  \mathbf{W} \cdot \mathbf{X} + \mathbf{b} 
&= \begin{bmatrix}
w\_{11} & w\_{12} &  \cdots & w\_{1m} \\\\
w\_{21} & w\_{22} & \cdots & w\_{2m} \\\\
w\_{31} & w\_{32} & \cdots & w\_{3m}
\end{bmatrix} \cdot
\begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
\vdots \\\\
x\_m
\end{bmatrix} + 
\begin{bmatrix}
b\_1 \\\\
b\_2 \\\\
b\_3
\end{bmatrix} = \\\\
&= 
\begin{bmatrix}
w\_{11} x\_1 + w\_{12} x\_2 +  \cdots + w\_{1m} x\_m + b\_1 \\\\
w\_{21} x\_1 + w\_{22} x\_2 +  \cdots + w\_{2m} x\_m + b\_2 \\\\
w\_{31} x\_1 + w\_{32} x\_2 +  \cdots + w\_{3m} x\_m + b\_3 
\end{bmatrix} = \begin{bmatrix}
z\_1 \\\\
z\_2 \\\\
z\_3
\end{bmatrix}
\end{aligned}}$$

]

---


class: middle

.center[
.width-100[![](figures/lec1/dense.png)]
]

.footnote[Slide source: [MIT 6.S191](http://introtodeeplearning.com/)]

---

class: middle

.smaller-x[–û—Å–∫—ñ–ª—å–∫–∏ –≤—Å—ñ –≤—Ö–æ–¥–∏ —â—ñ–ª—å–Ω–æ –∑‚Äô—î–¥–Ω–∞–Ω—ñ –∑ —É—Å—ñ–º–∞ –≤–∏—Ö–æ–¥–∞–º–∏, —Ü—ñ —à–∞—Ä–∏ –Ω–∞–∑–∏–≤–∞—é—Ç—å—Å—è *Dense*]

.center[
.width-100[![](figures/lec1/multiOuptupTF.png)]
]

$$z\_j = \sum\_{n=1}^{m} w\_{j, n} x\_n  + b\_j$$

---

class: blue-slide, middle, center
count: false

.larger-xx[–ë–∞–≥–∞—Ç–æ—à–∞—Ä–æ–≤–∏–π –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω]

---

class: middle

# –ë–∞–≥–∞—Ç–æ—à–∞—Ä–æ–≤–∏–π –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω

.center[
.width-100[![](figures/lec1/2layer.png)]
]

---

class: middle

# –ú–µ—Ä–µ–∂–∞ –∑ –æ–¥–Ω–∏–º –ø—Ä–∏—Ö–æ–≤–∞–Ω–∏–º —à–∞—Ä–æ–º

.center[
.width-100[![](figures/lec1/twoCode.png)]
]

---

class: middle

## –ú–µ—Ä–µ–∂–∞ –∑ –æ–¥–Ω–∏–º –ø—Ä–∏—Ö–æ–≤–∞–Ω–∏–º —à–∞—Ä–æ–º
.center[
.width-60[![](figures/lec1/2layer.png)]
]

.smaller-xx[
$$\begin{aligned}
\mathbf{X} = \begin{bmatrix}
x\_1  \\\\
x\_2  \\\\
x\_3
\end{bmatrix} 
&&
\mathbf{W}^{[1]} = \begin{bmatrix}
w\_{11} & w\_{12} &  w\_{13} \\\\
w\_{21} & w\_{22} &  w\_{23} \\\\
w\_{31} & w\_{32} &  w\_{33} \\\\
w\_{41} & w\_{42} &  w\_{43}
\end{bmatrix}
&& 
\mathbf{b}^{[1]} = \begin{bmatrix}
b\_1 \\\\
b\_2 \\\\
b\_3 \\\\
b\_4
\end{bmatrix}
&&
\mathbf{W}^{[2]} = \begin{bmatrix}
w\_{1} & w\_{2} &  w\_{3} & w\_{4} 
\end{bmatrix}
&& 
b^{[2]} = b
\end{aligned}$$


$$\boxed{\begin{aligned}
\mathbf{z}^{[1]} &= \mathbf{W}^{[1]} \cdot \mathbf{X} + \mathbf{b}^{[1]} \\\\
\mathbf{a}^{[1]} &= g^{[1]}(\mathbf{z}^{[1]}) \\\\
z^{[2]} &= \mathbf{W}^{[2]} \cdot \mathbf{a}^{[1]} + b^{[2]} \\\\
\hat y &= a^{[2]} = g^{[2]}(z^{[2]})
\end{aligned}}$$
]

---


class: middle

# –ì–ª–∏–±–∏–Ω–Ω–∞ –Ω–µ–π—Ä–æ–Ω–Ω–∞ –º–µ—Ä–µ–∂–∞

.center[
.width-100[![](figures/lec1/MLP2.png)]
]

---


class: end-slide, center
count: false

.larger-xx[–ö—ñ–Ω–µ—Ü—å]

---

count: false

# –õ—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∞

- LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. nature, 521(7553), 436-444.
